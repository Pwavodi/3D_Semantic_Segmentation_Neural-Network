{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Semantic Segmentation Models\n",
    "\n",
    "TASK: Create Pipeline to perform semantic segmentation on point clouds of indoor spaces.    \n",
    "\n",
    "This is because the LAYERS CASE STUDY deals with a sport facility.\n",
    "\n",
    "WORKFLOW TO SOLVE THE PROBLEM:\n",
    "1. Loading the Pretrianed Dataset that was downloaded from the https://cvg-data.inf.ethz.ch/s3dis/ \n",
    "2. Data Preprocessing.\n",
    "3. This pipeline will incorporate a pretrained segmentation Point Net to get predictions for an input set of points.\n",
    "4. Then open3d library will be used to search the point cloud space.\n",
    "5. Convert Individual Semantic to Meshes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMPORT LIBRARIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-10T04:49:38.863224Z",
     "start_time": "2023-07-10T04:49:33.789243Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pwavodij/opt/anaconda3/lib/python3.9/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: dlopen(/Users/pwavodij/opt/anaconda3/lib/python3.9/site-packages/torchvision/image.so, 0x0006): Symbol not found: __ZN2at4_ops19empty_memory_format4callEN3c108ArrayRefIxEENS2_8optionalINS2_10ScalarTypeEEENS5_INS2_6LayoutEEENS5_INS2_6DeviceEEENS5_IbEENS5_INS2_12MemoryFormatEEE\n",
      "  Referenced from: <AFB7C78A-1D52-38B1-9D33-93A75FA7D528> /Users/pwavodij/opt/anaconda3/lib/python3.9/site-packages/torchvision/image.so\n",
      "  Expected in:     <89972BE7-3028-34DA-B561-E66870D59767> /Users/pwavodij/opt/anaconda3/lib/python3.9/site-packages/torch/lib/libtorch_cpu.dylib\n",
      "  warn(f\"Failed to load image Python extension: {e}\")\n"
     ]
    }
   ],
   "source": [
    "import os # OS module in Python provides functions for interacting with the operating system\n",
    "from pathlib import Path # makes the Path class available to our program\n",
    "import re    # let you check if a particular string matches a given regular expression\n",
    "import glob  #  finds all the pathnames matching a specified pattern \n",
    "import random  # series of functions for or manipulating random integers.\n",
    "import numpy as np # used to perform a wide variety of mathematical operations on arrays\n",
    "import pandas as pd # \n",
    "\n",
    "import torch   #provides two high-level features: Tensor computation (like NumPy) with strong GPU acceleration. \n",
    "                #Deep neural networks built on a tape-based autograd system\n",
    "import torch.nn as nn   #gives us access to some helpful neural network things\n",
    "import torch.nn.functional as F     \n",
    "import torchmetrics     # a collection of machine learning metrics for distributed, \n",
    "                          # scalable PyTorch models and an easy-to-use API to create custom metrics\n",
    "from torchmetrics.classification import MulticlassMatthewsCorrCoef #s a measurement to measure the quality of a binary classificatio         \n",
    "\n",
    "import open3d as op3        #is an open-source library that supports rapid development of software that \n",
    "                            # deals with 3D data\n",
    "import matplotlib.pyplot as plt #is a collection of command style functions that make matplotlib work like MATLAB\n",
    "from torch.utils.data import Dataset \n",
    "import h5py #provides both a high- and low-level interface to the HDF5 library from Python\n",
    "\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-10T04:49:38.872310Z",
     "start_time": "2023-07-10T04:49:38.865482Z"
    }
   },
   "outputs": [],
   "source": [
    "# TEMP for supressing pytorch user warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SETTING THE FOLDER PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-10T04:49:38.878653Z",
     "start_time": "2023-07-10T04:49:38.874473Z"
    }
   },
   "outputs": [],
   "source": [
    "if Path.home().name in ['pwavodij']: # Joshua : This can be adapted for any user based on the file path to folder location\n",
    "    Dropbox = Path(Path.home(), 'Dropbox', 'Case_Study_LAYERS','3D_main_2')\n",
    "\n",
    "    # Define the main folder containing the subfolders with .txt files\n",
    "main_folder = Path(Dropbox, 'Reduced_Aligned_Versions')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting the Points_cloud and targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-10T04:53:43.883767Z",
     "start_time": "2023-07-10T04:49:40.660182Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Point clouds shape: (805188991, 3)\n",
      "Targets shape: (805188991,)\n"
     ]
    }
   ],
   "source": [
    "# Create empty lists to store the point cloud data\n",
    "point_clouds = []\n",
    "targets = []\n",
    "# Iterate over the subfolders in the main folder\n",
    "for subfolder in main_folder.iterdir():\n",
    "    # Check if the item is a directory\n",
    "    if subfolder.is_dir():\n",
    "        # Iterate over the HDF5 files in the subfolder and its sub-subfolders\n",
    "        for hdf5_file in subfolder.rglob('*.hdf5'):\n",
    "            # Load the HDF5 dataset\n",
    "            with h5py.File(hdf5_file, 'r') as hf:\n",
    "                # Get the points and targets datasets\n",
    "                points = hf['points'][:]\n",
    "                target_labels = hf['targets'][:]\n",
    "\n",
    "            # Append the points and targets to the respective lists\n",
    "            point_clouds.append(points)\n",
    "            targets.append(target_labels)\n",
    "\n",
    "# Check if any datasets were loaded\n",
    "if len(point_clouds) > 0 and len(targets) > 0:\n",
    "    # Convert the lists to NumPy arrays\n",
    "    point_clouds = np.concatenate(point_clouds, axis=0)\n",
    "    targets = np.concatenate(targets, axis=0)\n",
    "\n",
    "    # Example usage: Print the shape of the point clouds and targets arrays\n",
    "    print(\"Point clouds shape:\", point_clouds.shape)\n",
    "    print(\"Targets shape:\", targets.shape)\n",
    "else:\n",
    "    print(\"No datasets found in the directory.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining Labels and Color Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-10T04:53:43.926535Z",
     "start_time": "2023-07-10T04:53:43.905915Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "CATEGORIES = {\n",
    "    'ceiling'  : 0, 'floor'    : 1, 'wall'     : 2, 'beam'     : 3, \n",
    "    'column'   : 4, 'window'   : 5,'door'     : 6, 'table'    : 7, \n",
    "    'chair'    : 8, 'sofa'     : 9, 'bookcase' : 10, 'board'    : 11,\n",
    "    'stairs'   : 12,'clutter'  : 13\n",
    "                                    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-10T04:53:43.947389Z",
     "start_time": "2023-07-10T04:53:43.930209Z"
    }
   },
   "outputs": [],
   "source": [
    "# unique color map generated via\n",
    "# https://mokole.com/palette.html\n",
    "COLOR_MAP = {\n",
    "    0  : (47, 79, 79),    # ceiling - darkslategray\n",
    "    1  : (139, 69, 19),   # floor - saddlebrown\n",
    "    2  : (34, 139, 34),   # wall - forestgreen\n",
    "    3  : (75, 0, 130),    # beam - indigo\n",
    "    4  : (255, 0, 0),     # column - red \n",
    "    5  : (255, 255, 0),   # window - yellow\n",
    "    6  : (0, 255, 0),     # door - lime\n",
    "    7  : (0, 255, 255),   # table - aqua\n",
    "    8  : (0, 0, 255),     # chair - blue\n",
    "    9  : (255, 0, 255),   # sofa - fuchsia\n",
    "    10 : (238, 232, 170), # bookcase - palegoldenrod\n",
    "    11 : (100, 149, 237), # board - cornflower\n",
    "    12 : (255, 105, 180), # stairs - hotpink\n",
    "    13 : (0, 0, 0)        # clutter - black\n",
    "}\n",
    "\n",
    "def map_colors(x):\n",
    "    try:\n",
    "        return COLOR_MAP[x]\n",
    "    except KeyError:\n",
    "        # Handle the case where target value is not found in COLOR_MAP\n",
    "        # Assign a default color or specify a custom behavior\n",
    "        return (0, 0, 0)  # Default color (black)\n",
    "\n",
    "v_map_colors = np.vectorize(map_colors)\n",
    "# v_map_colors = np.vectorize(lambda x : COLOR_MAP[x])\n",
    "\n",
    "NUM_CLASSES = len(CATEGORIES)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODEL_ARTIFICIAL NEURAL NETWORK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## POINT CLOUD GEOMETRY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-07-10T04:49:50.411Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the data into training, validation, and test sets\n",
    "X_train, X_val_test, y_train, y_val_test = train_test_split(\n",
    "    point_clouds, targets, test_size=0.3, random_state=42\n",
    ")\n",
    "X_val, X_test, y_val, y_test = train_test_split(\n",
    "    X_val_test, y_val_test, test_size=0.5, random_state=42\n",
    ")\n",
    "\n",
    "\n",
    "print(\"Training set shapes:\")\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"y_train shape:\", y_train.shape)\n",
    "\n",
    "print(\"\\nValidation set shapes:\")\n",
    "print(\"X_val shape:\", X_val.shape)\n",
    "print(\"y_val shape:\", y_val.shape)\n",
    "\n",
    "print(\"\\nTest set shapes:\")\n",
    "print(\"X_test shape:\", X_test.shape)\n",
    "print(\"y_test shape:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-07-10T04:49:53.029Z"
    }
   },
   "outputs": [],
   "source": [
    "# point_clouds = X_test\n",
    "point_clouds = X_test\n",
    "pcd = op3.geometry.PointCloud()   #creates an empty point cloud object using the Point Cloud class from the open3d.geometry\n",
    "pcd.points = op3.utility.Vector3dVector(np.asarray(point_clouds))   # assigns the point_clouds array to the points attribute of the pcd object\n",
    "\n",
    "# # Access the points attribute of the point cloud object\n",
    "# points = np.asarray(pcd.points)\n",
    "# points.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-07-10T04:49:54.150Z"
    }
   },
   "outputs": [],
   "source": [
    "## assigns color values to the points in the pcd object based on the targets array\n",
    "targets = np.asarray(targets)\n",
    "pcd.colors = op3.utility.Vector3dVector(np.vstack(v_map_colors(targets)).T/255)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-10T00:29:05.429025Z",
     "start_time": "2023-07-10T00:29:05.426534Z"
    }
   },
   "outputs": [],
   "source": [
    "# Visualization\n",
    "# op3.visualization.draw_plotly(pcd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pretrained ML\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-10T00:29:45.989332Z",
     "start_time": "2023-07-10T00:29:45.949353Z"
    }
   },
   "outputs": [],
   "source": [
    "# Point_net module is the function that implements the PointNet Neural Network Workfow\n",
    "from point_net import PointNetSegHead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-10T00:29:46.994617Z",
     "start_time": "2023-07-10T00:29:46.984585Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cpu'"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the hardware that the computation will run through\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu' # is used to determine the device (CPU or CUDA GPU) that will be used for running the computations in PyTorch.\n",
    "DEVICE    \n",
    "         \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In my case I don't have a GPU rather using the CPU.    \n",
    "Already I envisaged there will be alot of computational issues this will affect the entire workflow. Already it has been observed above.!!!!    \n",
    "\n",
    "FIRST RECOMMENDATION.                \n",
    "Such Deep Neural Network Workflow Should be done on a GPU or TPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-10T01:06:59.597797Z",
     "start_time": "2023-07-10T01:06:59.533295Z"
    }
   },
   "outputs": [],
   "source": [
    "# feature selection hyperparameters\n",
    "# Total Number of files 19096 \n",
    "# You can decide the choice of dataset for training, validation and test\n",
    "NUM_TRAIN_POINTS = 4096 # train/valid points\n",
    "NUM_TEST_POINTS = 15000\n",
    "BATCH_SIZE = 16\n",
    "\n",
    "# loading a pre-trained PointNetSegHead model and preparing it for evaluation.\n",
    "\n",
    "MODEL_PATH = Path(Dropbox, 'trained_models','seg_focal','seg_model_60.pth') # get intitial model architecture\n",
    "\n",
    "model = PointNetSegHead(num_points=NUM_TEST_POINTS, m=NUM_CLASSES).to(DEVICE)\n",
    "model.load_state_dict(torch.load(MODEL_PATH, map_location=torch.device('cpu')))\n",
    "model.eval();\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detection pipeline\n",
    "\n",
    "Defining the object detection pipeline.\n",
    "\n",
    "Predicted classes within a 0.2m radius, then if the resulting cluster contains more than 1500 points, then the clusters bounding boxe is added to a list of proposals. \n",
    "\n",
    "\n",
    "Compute the average point score for each proposed object, by taking the total number of points assigned to the object divided by the total number of evaluated in the radius.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-07-10T05:24:25.028Z"
    }
   },
   "source": [
    "#LAYERS PREDICTION MODEL "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement the searching with open3d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-10T00:33:54.809981Z",
     "start_time": "2023-07-10T00:32:23.284518Z"
    }
   },
   "outputs": [],
   "source": [
    "# Reshape the points into an Nx3 array\n",
    "pcd_points = np.asarray(pcd.points)  # Convert to NumPy array\n",
    "pcd_points = pcd_points.reshape(-1, 3)  # Reshape to Nx3\n",
    "\n",
    "# Place them into a point cloud object\n",
    "pcd = op3.geometry.PointCloud()\n",
    "pcd.points = op3.utility.Vector3dVector(pcd_points)\n",
    "\n",
    "# Initialize KD tree object\n",
    "pcd_tree = op3.geometry.KDTreeFlann(pcd)\n",
    "\n",
    "# Perform search over radius r = 0.2\n",
    "[k, idx, a] = pcd_tree.search_radius_vector_3d(pcd.points[1500], 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-10T00:34:13.339031Z",
     "start_time": "2023-07-10T00:34:13.335091Z"
    }
   },
   "outputs": [],
   "source": [
    "# The function first checks if the length of points is greater than npoints. \n",
    "#This condition is used to determine whether downsampling is necessary. \n",
    "# If len(points) is already less than or equal to npoints, \n",
    "# downsampling is not required, and the function will return all the available indices.\n",
    "\n",
    "def get_downsample_choices(points, npoints):\n",
    "    if len(points) > npoints:\n",
    "        choice = np.random.choice(len(points), npoints, replace=False)\n",
    "    else:\n",
    "        choice = np.random.choice(len(points), npoints, replace=True)\n",
    "\n",
    "    return choice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-10T01:10:05.431035Z",
     "start_time": "2023-07-10T01:10:02.793602Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def get_predictions(predictions, points, cat, npoints=15000, radius=0.2, M=500):\n",
    "    predictions = predictions.reshape(-1).to('cpu')  # Nx1\n",
    "    pcd_points = points.permute(2, 0, 1).reshape(3, -1).to('cpu').T  # Nx3\n",
    "\n",
    "    # Downsample points\n",
    "    choice = np.random.choice(len(pcd_points), npoints, replace=False)\n",
    "    pcd_points = pcd_points[choice]\n",
    "    predictions = predictions[choice]\n",
    "\n",
    "    # Obtain points for the current category\n",
    "    pcd_points = pcd_points[predictions == cat]\n",
    "\n",
    "    # Place them into a point cloud object\n",
    "    pcd = op3.geometry.PointCloud()\n",
    "    pcd.points = op3.utility.Vector3dVector(pcd_points)\n",
    "\n",
    "    # Initialize KD tree object\n",
    "    pcd_tree = op3.geometry.KDTreeFlann(pcd)\n",
    "\n",
    "    # Perform M proposal searches over radius\n",
    "    p_idxs = np.random.choice(len(pcd_points), M, replace=False)\n",
    "\n",
    "    # Lists to store the results\n",
    "    neighbor_indices = []\n",
    "    neighbor_points = []\n",
    "\n",
    "    for p in p_idxs:\n",
    "        [k, idx, _] = pcd_tree.search_radius_vector_3d(pcd.points[p], radius=radius)\n",
    "        neighbor_indices.append(idx)\n",
    "        neighbor_points.append(pcd.points[idx])\n",
    "\n",
    "    return neighbor_indices, neighbor_points\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CREATE MESH FOR POINT CLOUD CATEGORY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-10T01:10:59.716984Z",
     "start_time": "2023-07-10T01:10:59.713998Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create an empty list to store the meshes\n",
    "meshes = []\n",
    "num_categories=1170\n",
    "# Iterate over each category\n",
    "for cat in range(num_categories):  # Replace num_categories with the actual number of categories\n",
    "    # Filter points for the current category\n",
    "    category_points = pcd_points[predictions == cat]\n",
    "\n",
    "    # Create a point cloud object for the current category\n",
    "    category_pcd = op3.geometry.PointCloud()\n",
    "    category_pcd.points = o3d.utility.Vector3dVector(category_points)\n",
    "\n",
    "    # Assign color to the points of the current category\n",
    "    color = color_map.get(cat, [0, 0, 1])  # Blue color for unknown categories\n",
    "    category_pcd.paint_uniform_color(color)\n",
    "\n",
    "    # Create a mesh from the point cloud\n",
    "    mesh = op3.geometry.TriangleMesh.create_from_point_cloud_poisson(category_pcd, depth=8)\n",
    "\n",
    "    # Append the mesh to the list\n",
    "    meshes.append(mesh)\n",
    "\n",
    "# Visualization: Render all the meshes\n",
    "o3d.visualization.draw_geometries(meshes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SAVE AND EXPORT MESH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-07-10T05:41:32.919Z"
    }
   },
   "outputs": [],
   "source": [
    "import pyfbx\n",
    "scene = pyfbx.FbxScene()\n",
    "mesh_node = scene.create_mesh_node('mesh') # Create an FBX mesh node\n",
    "mesh_node.set_mesh_data(vertices, faces, normals) # Set the mesh data\n",
    "scene.save('mesh.fbx') # Save the scene as an FBX file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-10T00:34:18.487255Z",
     "start_time": "2023-07-10T00:34:18.480709Z"
    }
   },
   "outputs": [],
   "source": [
    "# def get_predictions(predictions, points, cat, npoints=15000, radius=0.2, M=500):\n",
    "#     predictions = pred_choice.reshape(-1).to('cpu') # Nx1\n",
    "#     pcd_points = norm_points.permute(2, 0, 1).reshape(3, -1).to('cpu').T # Nx3\n",
    "\n",
    "#     # downsample points\n",
    "#     choice = np.random.choice(len(pcd_points), 15000, replace=False)\n",
    "#     pcd_points = pcd_points[choice]\n",
    "#     predictions = predictions[choice]\n",
    "\n",
    "#     # only obtain points for current category\n",
    "#     pcd_points = pcd_points[predictions == cat]\n",
    "\n",
    "#     # place them into a point cloud object\n",
    "#     pcd = op3.geometry.PointCloud()\n",
    "#     pcd.points = op3.utility.Vector3dVector(pcd_points)\n",
    "\n",
    "#     # initialize KD tree object\n",
    "#     pcd_tree = op3.geometry.KDTreeFlann(pcd)\n",
    "\n",
    "#     # perform M proposal searches over radius \n",
    "#     p_idxs = np.random.choice(len(pcd_points), M, replace=False)\n",
    "#     for p in p_idxs:\n",
    "#         [k, idx, _] = pcd_tree.search_radius_vector_3d(pcd.points[p], radius=radius)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "vscode": {
   "interpreter": {
    "hash": "0a54084e6b208ee8d1ce3989ffc20924477a5f55f5a43e22e699a6741623861e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
